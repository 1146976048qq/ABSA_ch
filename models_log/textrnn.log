
0it [00:00, ?it/s]
2287it [00:00, 22864.90it/s]
4701it [00:00, 23231.37it/s]
7144it [00:00, 23577.01it/s]
9643it [00:00, 23980.89it/s]
12169it [00:00, 24336.07it/s]
14222it [00:00, 19822.48it/s]
16229it [00:00, 19893.92it/s]
18931it [00:00, 21601.52it/s]
21544it [00:00, 22784.07it/s]
24128it [00:01, 23622.12it/s]
26578it [00:01, 23876.40it/s]
29231it [00:01, 24612.51it/s]
31864it [00:01, 25102.42it/s]
34523it [00:01, 25528.94it/s]
36850it [00:01, 23957.68it/s]

0it [00:00, ?it/s]
1652it [00:00, 13247.66it/s]
3020it [00:00, 13371.13it/s]
4423it [00:00, 13561.20it/s]
4940it [00:00, 13633.12it/s]

0it [00:00, ?it/s]
1963it [00:00, 19627.35it/s]
4406it [00:00, 20854.75it/s]
4940it [00:00, 22049.35it/s]
/data/kkzhang/miniconda3/envs/absa/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Loading data...
Vocab size: 4762
Time usage: 0:00:02
<bound method Module.parameters of Model(
  (embedding): Embedding(4762, 300)
  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)
  (fc): Linear(in_features=256, out_features=3, bias=True)
)>
Epoch [1/10]
Iter:      0,  Train Loss:   1.1,  Train Acc: 19.53%,  Val Loss:   1.0,  Val Acc: 77.75%,  Time: 0:00:00 *
Iter:    100,  Train Loss:  0.69,  Train Acc: 78.12%,  Val Loss:  0.66,  Val Acc: 77.78%,  Time: 0:00:02 *
Iter:    200,  Train Loss:  0.68,  Train Acc: 76.56%,  Val Loss:  0.63,  Val Acc: 77.94%,  Time: 0:00:03 *
Epoch [2/10]
Iter:    300,  Train Loss:  0.72,  Train Acc: 75.00%,  Val Loss:  0.63,  Val Acc: 78.02%,  Time: 0:00:05 *
Iter:    400,  Train Loss:  0.57,  Train Acc: 84.38%,  Val Loss:  0.62,  Val Acc: 78.62%,  Time: 0:00:07 *
Iter:    500,  Train Loss:  0.67,  Train Acc: 78.91%,  Val Loss:  0.63,  Val Acc: 78.82%,  Time: 0:00:08 
Epoch [3/10]
Iter:    600,  Train Loss:  0.58,  Train Acc: 78.91%,  Val Loss:  0.61,  Val Acc: 78.74%,  Time: 0:00:10 *
Iter:    700,  Train Loss:  0.48,  Train Acc: 84.38%,  Val Loss:  0.61,  Val Acc: 78.89%,  Time: 0:00:11 *
Iter:    800,  Train Loss:  0.55,  Train Acc: 82.03%,  Val Loss:  0.62,  Val Acc: 78.47%,  Time: 0:00:13 
Epoch [4/10]
Iter:    900,  Train Loss:  0.44,  Train Acc: 85.94%,  Val Loss:  0.62,  Val Acc: 78.82%,  Time: 0:00:14 
Iter:   1000,  Train Loss:  0.63,  Train Acc: 71.88%,  Val Loss:  0.61,  Val Acc: 78.84%,  Time: 0:00:16 
Iter:   1100,  Train Loss:   0.5,  Train Acc: 82.03%,  Val Loss:  0.61,  Val Acc: 78.54%,  Time: 0:00:17 
Epoch [5/10]
Iter:   1200,  Train Loss:  0.65,  Train Acc: 77.34%,  Val Loss:  0.63,  Val Acc: 78.47%,  Time: 0:00:19 
Iter:   1300,  Train Loss:  0.41,  Train Acc: 87.50%,  Val Loss:  0.65,  Val Acc: 78.10%,  Time: 0:00:20 
Iter:   1400,  Train Loss:  0.53,  Train Acc: 79.69%,  Val Loss:  0.66,  Val Acc: 77.16%,  Time: 0:00:22 
Epoch [6/10]
Iter:   1500,  Train Loss:  0.55,  Train Acc: 80.47%,  Val Loss:  0.65,  Val Acc: 78.17%,  Time: 0:00:23 
Iter:   1600,  Train Loss:  0.52,  Train Acc: 82.81%,  Val Loss:  0.68,  Val Acc: 77.43%,  Time: 0:00:25 
Iter:   1700,  Train Loss:  0.64,  Train Acc: 77.34%,  Val Loss:  0.66,  Val Acc: 78.17%,  Time: 0:00:26 
No optimization for a long time, auto-stopping...
Test Loss:   0.6,  Test Acc: 79.65%

Time usage: 0:00:00
